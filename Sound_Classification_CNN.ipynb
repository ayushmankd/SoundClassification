{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sound Classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OqiqFjVXM_X_"
      },
      "source": [
        "Helper Function to get Sound File Properties"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbfMxZ_hMqWq"
      },
      "source": [
        "import struct\n",
        "def read_file_properties(self, filename):\n",
        "  wave_file = open(filename,\"rb\")\n",
        "        \n",
        "  riff = wave_file.read(12)\n",
        "  fmt = wave_file.read(36)\n",
        "        \n",
        "  num_channels_string = fmt[10:12]\n",
        "  num_channels = struct.unpack('<H', num_channels_string)[0]\n",
        "\n",
        "  sample_rate_string = fmt[12:16]\n",
        "  sample_rate = struct.unpack(\"<I\",sample_rate_string)[0]\n",
        "    \n",
        "  bit_depth_string = fmt[22:24]\n",
        "  bit_depth = struct.unpack(\"<H\",bit_depth_string)[0]\n",
        "\n",
        "  return (num_channels, sample_rate, bit_depth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5xNvn84QHTz"
      },
      "source": [
        "Helper Function to convert sound file to MFCC form"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2BMWl78QNge"
      },
      "source": [
        "import numpy as np\n",
        "max_pad_len = 174\n",
        "\n",
        "def extract_features(file_name):\n",
        "   \n",
        "    try:\n",
        "        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n",
        "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
        "        pad_width = max_pad_len - mfccs.shape[1]\n",
        "        mfccs = np.pad(mfccs, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(\"Error encountered while parsing file: \", file_name)\n",
        "        return None \n",
        "     \n",
        "    return mfccs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RrGwP8mlUFPG"
      },
      "source": [
        "Download Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4WH8qN8UHRK"
      },
      "source": [
        "!wget 'https://zenodo.org/record/1203745/files/UrbanSound8K.tar.gz'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndT3hv1_XsBe"
      },
      "source": [
        "!tar xvzf './UrbanSound8K.tar.gz'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdiESHdgO3lj"
      },
      "source": [
        "Data Preprocessing "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mw5sR0uaNUTT"
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import librosa\n",
        "\n",
        "# Set the path to the full UrbanSound dataset \n",
        "fulldatasetpath = './UrbanSound8K/audio/'\n",
        "\n",
        "metadata = pd.read_csv('./UrbanSound8K/metadata/UrbanSound8K.csv')\n",
        "metadata = metadata[0:1000]\n",
        "print (metadata.shape)\n",
        "features = []\n",
        "# Iterate through each sound file and extract the features \n",
        "for index, row in metadata.iterrows():\n",
        "    \n",
        "    file_name = os.path.join(os.path.abspath(fulldatasetpath),'fold'+str(row[\"fold\"])+'/',str(row[\"slice_file_name\"]))\n",
        "    \n",
        "    class_label = row[\"class\"]\n",
        "    data = extract_features(file_name)\n",
        "    \n",
        "    features.append([data, class_label])\n",
        "# Convert into a Panda dataframe \n",
        "featuresdf = pd.DataFrame(features, columns=['feature','class_label'])\n",
        "\n",
        "print('Finished feature extraction from ', len(featuresdf), ' files')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WKf8ivIQsix"
      },
      "source": [
        "Label Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AusmQfM0QvjS"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "# Convert features and corresponding classification labels into numpy arrays\n",
        "X = np.array(featuresdf.feature.tolist())\n",
        "y = np.array(featuresdf.class_label.tolist())\n",
        "\n",
        "# Encode the classification labels\n",
        "le = LabelEncoder()\n",
        "yy = to_categorical(le.fit_transform(y))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xahqj8_fQ3Ln"
      },
      "source": [
        "Train Test Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGal0fd0Q5Fx"
      },
      "source": [
        "from sklearn.model_selection import train_test_split \n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, yy, test_size=0.2, random_state = 42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Y-KeZN6SV1P"
      },
      "source": [
        "Preparing our CNN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BaIiUE-SZol"
      },
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Convolution2D, Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import np_utils\n",
        "from sklearn import metrics \n",
        "\n",
        "num_rows = 40\n",
        "num_columns = 174\n",
        "num_channels = 1\n",
        "\n",
        "x_train = x_train.reshape(x_train.shape[0], num_rows, num_columns, num_channels)\n",
        "x_test = x_test.reshape(x_test.shape[0], num_rows, num_columns, num_channels)\n",
        "\n",
        "num_labels = yy.shape[1]\n",
        "filter_size = 2\n",
        "\n",
        "# Construct model \n",
        "model = Sequential()\n",
        "model.add(Conv2D(filters=16, kernel_size=2, input_shape=(num_rows, num_columns, num_channels), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv2D(filters=32, kernel_size=2, activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv2D(filters=64, kernel_size=2, activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv2D(filters=128, kernel_size=2, activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(GlobalAveragePooling2D())\n",
        "\n",
        "model.add(Dense(num_labels, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OC1LTmv9S4kV"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Puem_P6DS_Hz"
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint \n",
        "from datetime import datetime \n",
        "\n",
        "#num_epochs = 12\n",
        "#num_batch_size = 128\n",
        "\n",
        "num_epochs = 72\n",
        "num_batch_size = 256\n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.basic_cnn.hdf5', \n",
        "                               verbose=1, save_best_only=True)\n",
        "start = datetime.now()\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(x_test, y_test), callbacks=[checkpointer], verbose=1)\n",
        "\n",
        "\n",
        "duration = datetime.now() - start\n",
        "print(\"Training completed in time: \", duration)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTeFiRSUTGYv"
      },
      "source": [
        "Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOBhrY0iTHbT"
      },
      "source": [
        "score = model.evaluate(x_train, y_train, verbose=0)\n",
        "print(\"Training Accuracy: \", score[1])\n",
        "\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"Testing Accuracy: \", score[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhsR-lOCTX-9"
      },
      "source": [
        "Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pN_ivzHMTaiq"
      },
      "source": [
        "def print_prediction(file_name):\n",
        "    prediction_feature = extract_features(file_name) \n",
        "    prediction_feature = prediction_feature.reshape(1, num_rows, num_columns, num_channels)\n",
        "\n",
        "    predicted_vector = model.predict_classes(prediction_feature)\n",
        "    predicted_class = le.inverse_transform(predicted_vector) \n",
        "    print(\"The predicted class is:\", predicted_class[0], '\\n') \n",
        "\n",
        "    predicted_proba_vector = model.predict_proba(prediction_feature) \n",
        "    predicted_proba = predicted_proba_vector[0]\n",
        "    for i in range(len(predicted_proba)): \n",
        "        category = le.inverse_transform(np.array([i]))\n",
        "        print(category[0], \"\\t\\t : \", format(predicted_proba[i], '.32f') )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jK9ihFrofBol"
      },
      "source": [
        "# Test\n",
        "print (print_prediction('./siren_1.wav'))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}